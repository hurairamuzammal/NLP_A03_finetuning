{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e1f526",
   "metadata": {},
   "source": [
    "# Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate evaluate sacrebleu nltk torch sentencepiece\n",
    "!pip install -q git+https://github.com/microsoft/CodeBLEU.git || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, default_data_collator)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import sacrebleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seed=42\n",
    "random.seed(Seed)\n",
    "np.random.seed(Seed)\n",
    "os.environ['PYTHONHASHSEED']=str(Seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c4f37",
   "metadata": {},
   "source": [
    "# Import SPOC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0560485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the single dataset provided on Kaggle exactly as requested\n",
    "path = '/kaggle/input/psuedocode-and-python/dataSet.txt'\n",
    "assert os.path.exists(path), f'Dataset not found at {path}'\n",
    "# The file contains alternating <|pseudocode|> and <|code|> blocks. Parse them into pairs.\n",
    "with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    text = f.read()\n",
    "pairs = []\n",
    "# Split by the pseudocode marker and extract following code block\n",
    "for part in text.split('<|pseudocode|>'):\n",
    "    if '<|code|>' in part:\n",
    "        pseudo_part, rest = part.split('<|code|>', 1)\n",
    "        code_part = rest.split('<|pseudocode|>')[0] if '<|pseudocode|>' in rest else rest\n",
    "        pseudo = pseudo_part.strip()\n",
    "        code = code_part.strip()\n",
    "        if pseudo and code:\n",
    "            pairs.append({'pseudo': pseudo, 'code': code})\n",
    "df = pd.DataFrame(pairs)\n",
    "print('Parsed pairs:', len(df))\n",
    "print(df.head(5).to_dict(orient='records'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412d6a5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
